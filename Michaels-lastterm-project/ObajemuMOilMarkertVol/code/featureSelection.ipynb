{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/CL_F_data.csv')\n",
    "\n",
    "window = 5 # set Window to the past 5 days\n",
    "\n",
    "# Compute volatility over window -------------------------------------------------\n",
    "df['realized_vol']= df['log_return'].rolling(window).std() *np.sqrt(252)\n",
    "df['rolling_mean'] = df['log_return'].rolling(window).mean() # Rolling mean\n",
    "df['rolling_std'] = df['log_return'].rolling(window).std() # Rolling standard deviation\n",
    "\n",
    "# Add diffrent established volatility estimators -------------------------------------------------\n",
    "\n",
    "## 1) Parkisons volatility\n",
    "df['parkinson_vol'] = np.sqrt((1 / (4 * np.log(2))) * (np.log(df['High'] / df['Low']) ** 2)) \n",
    "\n",
    "## 2) Garman–Klass\n",
    "df['garman_klass'] = np.sqrt(\n",
    "    0.5 * (np.log(df['High'] / df['Low']) ** 2)\n",
    "  - (2 * np.log(2) - 1) * (np.log(df['Close'] / df['Open']) ** 2)\n",
    ")\n",
    "\n",
    "## 3) Rogers–Satchell\n",
    "df['rogers_satchell'] = np.sqrt(\n",
    "    (np.log(df['High'] / df['Open']) * \n",
    "     (np.log(df['High'] / df['Open']) - np.log(df['Close'] / df['Open'])))\n",
    "  + (np.log(df['Low']  / df['Open']) * \n",
    "     (np.log(df['Low']  / df['Open']) - np.log(df['Close'] / df['Open'])))\n",
    ")\n",
    "\n",
    "## 4) Yang–Zhang\n",
    "###   a) Overnight & open-to-close returns\n",
    "df['overnight_ret']    = np.log(df['Open'] / df['Close'].shift(1))\n",
    "df['open_close_ret']   = np.log(df['Close'] / df['Open'])\n",
    "\n",
    "###   b) rolling variances\n",
    "k = 0.34\n",
    "ov_var = df['overnight_ret'].rolling(window).var()       \n",
    "oc_var = df['open_close_ret'].rolling(window).var()      \n",
    "rs_var = df['rogers_satchell']**2                        \n",
    "\n",
    "###   c) combine and annualize by sqrt(252)\n",
    "yz_var = ov_var + k * oc_var + (1 - k) * rs_var\n",
    "df['yang_zhang'] = np.sqrt(yz_var * 252)\n",
    "\n",
    "## 5) Volume dynamics: daily percentage change in trading volume -------------------------------------------------\n",
    "df['volume_change'] = df['Volume'].pct_change()\n",
    "df = df.dropna() \n",
    "df['future_vol'] = df['realized_vol'].shift(-window)\n",
    "df = df.dropna()\n",
    "df['target'] = (df['future_vol'] > df['realized_vol']).astype(int)\n",
    "\n",
    "## 6) Add new features to improve AUC scores -------------------------------------------------\n",
    "df['return_lag1'] = df['log_return'].shift(1)\n",
    "df['volume_lag1'] = df['Volume'].shift(1)\n",
    "\n",
    "def rolling_stats(series, window):\n",
    "    return series.rolling(window).mean(), series.rolling(window).std()\n",
    "\n",
    "df['ma_5'], df['std_5'] = rolling_stats(df['log_return'], 5)\n",
    "df['ma_10'], df['std_10'] = rolling_stats(df['log_return'], 10)\n",
    "df['momentum_5'] = df['log_return'] - df['log_return'].shift(5)\n",
    "df['volatility_5'] = df['log_return'].rolling(5).std()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380064b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set predictors and target\n",
    "feature = ['log_return', 'rolling_mean', 'rolling_std',  'volume_change', \n",
    "            'parkinson_vol','garman_klass', 'rogers_satchell', 'yang_zhang',\n",
    "            'return_lag1', 'volume_lag1', 'ma_5', 'std_5', 'ma_10', 'std_10', \n",
    "            'momentum_5', 'volatility_5'\n",
    "            ]\n",
    "\n",
    "predictor = df[feature]\n",
    "target = df['target']\n",
    "\n",
    "# train/test split, shuffle set to false to be time-aware\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    predictor, target, test_size=1/5, shuffle=False\n",
    ")\n",
    "\n",
    "# scale your inputs\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# build and fit model\n",
    "model = LogisticRegression(\n",
    "    penalty='l2', C=1.0, solver='liblinear', class_weight='balanced'\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# extract and sort coefficients to see feature importance\n",
    "coef_df = (\n",
    "    pd.DataFrame({\n",
    "        'feature': feature,\n",
    "        'coef':    model.coef_[0]\n",
    "    })\n",
    "    .assign(abs_coef=lambda d: d.coef.abs())\n",
    "    .sort_values('abs_coef', ascending=False)\n",
    ")\n",
    "print(coef_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
