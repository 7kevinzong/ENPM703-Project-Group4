{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install libraries\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier as forest\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import learning_curve, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/CL_F_data.csv')\n",
    "\n",
    "window = 5 # set window to the past 5 days\n",
    "\n",
    "# Compute volatility over window -------------------------------------------------\n",
    "df['realized_vol']= df['log_return'].rolling(window).std() *np.sqrt(252)\n",
    "df['rolling_mean'] = df['log_return'].rolling(window).mean() # Rolling mean\n",
    "df['rolling_std'] = df['log_return'].rolling(window).std() # Rolling standard deviation\n",
    "\n",
    "# Add diffrent established volatility estimators -------------------------------------------------\n",
    "\n",
    "## 1) Parkisons volatility\n",
    "df['parkinson_vol'] = np.sqrt((1 / (4 * np.log(2))) * (np.log(df['High'] / df['Low']) ** 2)) \n",
    "\n",
    "## 2) Garman–Klass\n",
    "df['garman_klass'] = np.sqrt(\n",
    "    0.5 * (np.log(df['High'] / df['Low']) ** 2)\n",
    "  - (2 * np.log(2) - 1) * (np.log(df['Close'] / df['Open']) ** 2)\n",
    ")\n",
    "\n",
    "## 3) Rogers–Satchell\n",
    "df['rogers_satchell'] = np.sqrt(\n",
    "    (np.log(df['High'] / df['Open']) * \n",
    "     (np.log(df['High'] / df['Open']) - np.log(df['Close'] / df['Open'])))\n",
    "  + (np.log(df['Low']  / df['Open']) * \n",
    "     (np.log(df['Low']  / df['Open']) - np.log(df['Close'] / df['Open'])))\n",
    ")\n",
    "\n",
    "## 4) Yang–Zhang\n",
    "###   a) Overnight & open-to-close returns\n",
    "df['overnight_ret']    = np.log(df['Open'] / df['Close'].shift(1))\n",
    "df['open_close_ret']   = np.log(df['Close'] / df['Open'])\n",
    "\n",
    "###   b) rolling variances\n",
    "k = 0.34\n",
    "ov_var = df['overnight_ret'].rolling(window).var()       \n",
    "oc_var = df['open_close_ret'].rolling(window).var()      \n",
    "rs_var = df['rogers_satchell']**2                        \n",
    "\n",
    "###   c) combine and annualize by sqrt(252)\n",
    "yz_var = ov_var + k * oc_var + (1 - k) * rs_var\n",
    "df['yang_zhang'] = np.sqrt(yz_var * 252)\n",
    "\n",
    "## 5) Volume dynamics: daily percentage change in trading volume -------------------------------------------------\n",
    "df['volume_change'] = df['Volume'].pct_change()\n",
    "df = df.dropna() \n",
    "df['future_vol'] = df['realized_vol'].shift(-window)\n",
    "df = df.dropna()\n",
    "df['target'] = (df['future_vol'] > df['realized_vol']).astype(int)\n",
    "\n",
    "## 6) Add new features to improve AUC scores -------------------------------------------------\n",
    "df['return_lag1'] = df['log_return'].shift(1)\n",
    "df['volume_lag1'] = df['Volume'].shift(1)\n",
    "\n",
    "def rolling_stats(series, window):\n",
    "    return series.rolling(window).mean(), series.rolling(window).std()\n",
    "\n",
    "df['ma_5'], df['std_5'] = rolling_stats(df['log_return'], 5)\n",
    "df['ma_10'], df['std_10'] = rolling_stats(df['log_return'], 10)\n",
    "df['momentum_5'] = df['log_return'] - df['log_return'].shift(5)\n",
    "df['volatility_5'] = df['log_return'].rolling(5).std()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors and target\n",
    "\n",
    "predictors = df[[ 'rolling_std', 'yang_zhang', 'std_5', 'std_10', 'volatility_5'\n",
    "                  ]]\n",
    "target = df['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    predictors, target, \n",
    "    test_size=1/5, shuffle=False\n",
    ")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5) # A time series split allows for cross-validation that respects temporal order\n",
    "\n",
    "# Update KNN grid to ensure n_neighbors <= min training samples\n",
    "max_n_neighbors = min(len(X_train), len(y_train))  # Smallest training set size\n",
    "\n",
    "# Define models and small hyperparameter grids\n",
    "model_grids = {\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "        'grid':  {'max_depth': [3, 10, None]} # max_depth sets the maximum number of splits from the root of the lead\n",
    "                                              # controls complexity of the DT, shallow depths mean high bias, deep deeps means to many varience\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': forest(random_state=42, class_weight='balanced'),\n",
    "        'grid':  {'n_estimators': [50, 100, 200]}\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "        'grid':  {'C': [0.1, 1]}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': neighbors.KNeighborsClassifier(weights='distance'), # A distance weight treats closer points with greater influence \n",
    "        'grid':  {'n_neighbors': [n for n in [5, 10, 20, 30] if n <= max_n_neighbors]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(kernel='rbf',max_iter= 2000, probability=True, random_state=42),\n",
    "        'grid': {'C': [0.1, 1, 10], 'gamma': ['scale', 0.01, 0.1, 1, 'auto']}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "        'grid': {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMClassifier(max_depth= -1, random_state=42, verbosity=-1,),\n",
    "        'grid': {'n_estimators': [50, 100, 200, 500], 'num_leaves': [31, 63, 128], 'learning_rate': [0.01, 0.1]}\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "# Grid‐search each model\n",
    "for name, cfg in model_grids.items():\n",
    "    gs = GridSearchCV(cfg['model'], cfg['grid'], cv=tscv, scoring='roc_auc')\n",
    "    # scale the inputs where needed\n",
    "    if name in ('Logistic Regression','KNN', 'SVM' ):\n",
    "        gs.fit(X_train_scaled, y_train)\n",
    "    else:\n",
    "        gs.fit(X_train, y_train)\n",
    "    best_models[name] = gs.best_estimator_\n",
    "    print(f'{name} -- best parameter: {gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "\n",
    "## Decision Tree model\n",
    "tree = best_models['Decision Tree']\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "## Logistic Regression model\n",
    "logr = best_models['Logistic Regression']\n",
    "logr.fit(X_train_scaled , y_train)\n",
    "\n",
    "## Random Forest model\n",
    "rf = best_models['Random Forest']\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "## KNN model\n",
    "knn = best_models['KNN']\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "## SVM model\n",
    "svm = best_models['SVM']\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "## XGBoost model\n",
    "xg = best_models['XGBoost']\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "## LightGBM model\n",
    "gbm = best_models['LightGBM']\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "## Naive Bayes model for baseline\n",
    "nb_model = NB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "## Linear discriminant analysis model for baseline\n",
    "lda_model = LDA()\n",
    "lda_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to score models\n",
    "def getScore (X_test, y_test, model):\n",
    "\n",
    "    # Check which model is being scored and choose title\n",
    "    model_titles = {\n",
    "        tree: \"DT\", logr: \"LR\", nb_model: \"NB\",\n",
    "        lda_model: \"LDA\", rf: \"Forest\", svm: \"SVM\",\n",
    "        xg: \"XG Boost\", gbm: \"LightGBM\", knn: \"KNN\"\n",
    "    }\n",
    "\n",
    "    title = model_titles.get(model, \"XG\")\n",
    "    \n",
    "    names = ['negative', 'positive']\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Uncomment once model selection is complete\n",
    "    '''\n",
    "    # Ensure consistent lengths\n",
    "    if len(y_test) != len(y_pred):\n",
    "        raise ValueError(f\"Inconsistent lengths: y_test ({len(y_test)}) and y_pred ({len(y_pred)})\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=names)\n",
    "    plt.figure(figsize =(8, 6))\n",
    "    disp.plot(cmap =plt.cm.Greys)\n",
    "    plt.title(f'{title} Confusion Matrix')\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    # Calculating classification report, accuracy, average precision and recall across all classes\n",
    "    cf = metrics.classification_report(y_test, y_pred, zero_division=0, target_names=names)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "    recall = metrics.recall_score(y_test, y_pred, average='macro')  # True Positive Rate        \n",
    "\n",
    "    # Save the scores\n",
    "    with open(f'../out/{title}_scores.txt', \"w\") as f:\n",
    "        f.write(f\"Classification Report: \\n{cf}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "        f.write(f\"Precision (macro avg): {precision:.2f}\\n\")\n",
    "        f.write(f\"True Positive Rate (Recall - macro avg): {recall:.2f}\\n\")\n",
    "        \n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot area under curve\n",
    "def plotAuc (X_test, X_test_scaled, y_test, logr, tree, rf, lda, nb, knn, svm, xg, gbm):\n",
    "    \n",
    "    # Decision tree model\n",
    "    tree_probs = tree.predict_proba(X_test)[:, 1]\n",
    "    tree_fpr, tree_tpr, _ = roc_curve(y_test, tree_probs)\n",
    "    tree_roc_auc = auc(tree_fpr, tree_tpr)\n",
    "\n",
    "    # Logistic regression model\n",
    "    logr_probs = logr.predict_proba(X_test_scaled )[:, 1]\n",
    "    logr_fpr, logr_tpr, _ = roc_curve(y_test, logr_probs)\n",
    "    logr_roc_auc = auc(logr_fpr, logr_tpr)\n",
    "\n",
    "    # Bayes model\n",
    "    nb_probs = nb.predict_proba(X_test)[:, 1]\n",
    "    nb_fpr, nb_tpr, _ = roc_curve(y_test, nb_probs)\n",
    "    nb_roc_auc = auc(nb_fpr, nb_tpr)\n",
    "\n",
    "    # Linear discriminant analysis model\n",
    "    lda_probs = lda.predict_proba(X_test)[:, 1]\n",
    "    lda_fpr, lda_tpr, _ = roc_curve(y_test, lda_probs)\n",
    "    lda_roc_auc = auc(lda_fpr, lda_tpr)\n",
    "\n",
    "    # Random forest model\n",
    "    rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "    rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "    rf_roc_auc = auc(rf_fpr, rf_tpr)\n",
    "\n",
    "    # SVM model\n",
    "    svm_probs = svm.predict_proba(X_test_scaled)[:, 1]\n",
    "    svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_probs)\n",
    "    svm_roc_auc = auc(svm_fpr, svm_tpr)\n",
    "\n",
    "    # XG model\n",
    "    xg_probs = xg.predict_proba(X_test)[:, 1]\n",
    "    xg_fpr, xg_tpr, _ = roc_curve(y_test, xg_probs)\n",
    "    xg_roc_auc = auc(xg_fpr, xg_tpr)\n",
    "\n",
    "    # GBM model\n",
    "    gbm_probs = gbm.predict_proba(X_test)[:, 1]\n",
    "    gbm_fpr, gbm_tpr, _ = roc_curve(y_test, gbm_probs)\n",
    "    gbm_roc_auc = auc(gbm_fpr, gbm_tpr)    \n",
    "\n",
    "    # KNN model\n",
    "    knn_probs = knn.predict_proba(X_test_scaled)[:, 1]\n",
    "    knn_fpr, knn_tpr, _ = roc_curve(y_test, knn_probs)\n",
    "    knn_roc_auc = auc(knn_fpr, knn_tpr)\n",
    "\n",
    "    # Plot ROC Curves\n",
    "    plt.figure()\n",
    "    plt.plot(tree_fpr, tree_tpr, label=f'Decision Tree (AUC = {tree_roc_auc:.2f})')\n",
    "    plt.plot(logr_fpr, logr_tpr, label=f'Logistic Regression (AUC = {logr_roc_auc:.2f})')\n",
    "    plt.plot(nb_fpr, nb_tpr, label=f'Bayes (AUC = {nb_roc_auc:.2f})')\n",
    "    plt.plot(lda_fpr, lda_tpr, label=f'Linear discriminant analysis (AUC = {lda_roc_auc:.2f})')\n",
    "    plt.plot(rf_fpr, rf_tpr, label=f'Random Forest (AUC = {rf_roc_auc:.2f})')\n",
    "    plt.plot(knn_fpr, knn_tpr, label=f'SVM (AUC = {svm_roc_auc:.2f})')\n",
    "    plt.plot(knn_fpr, knn_tpr, label=f'XG Boost (AUC = {xg_roc_auc:.2f})')\n",
    "    plt.plot(knn_fpr, knn_tpr, label=f'Light GBM (AUC = {gbm_roc_auc:.2f})')\n",
    "    plt.plot(knn_fpr, knn_tpr, label=f'k-nearest neighbor (AUC = {knn_roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve Comparison')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Print AUC values\n",
    "    print(f'Decision Tree AUC: {tree_roc_auc:.3f}')\n",
    "    print(f'Logistic Regression AUC: {logr_roc_auc:.3f}')\n",
    "    print(f'Bayes AUC: {nb_roc_auc:.3f}')\n",
    "    print(f'Linear discriminat AUC: {lda_roc_auc:.3f}')\n",
    "    print(f'Random Forest AUC: {rf_roc_auc:.3f}')\n",
    "    print(f'SVM AUC = {svm_roc_auc:.2f})')\n",
    "    print(f'XG Boost AUC = {xg_roc_auc:.2f})')\n",
    "    print(f'Light GBM AUC = {gbm_roc_auc:.2f})')\n",
    "    print(f'k-nearest neighbor AUC: {knn_roc_auc:.3f}')    \n",
    "\n",
    "    # Save the AUC scores\n",
    "    with open(f'../out/AUC_scores.txt', \"w\") as f:\n",
    "        f.write(f'Decision Tree AUC: {tree_roc_auc:.3f}\\n')\n",
    "        f.write(f'Logistic Regression AUC: {logr_roc_auc:.3f}\\n')\n",
    "        f.write(f'Bayes AUC: {nb_roc_auc:.3f}\\n')\n",
    "        f.write(f'Linear discriminat AUC: {lda_roc_auc:.3f}\\n')\n",
    "        f.write(f'Random Forest AUC: {rf_roc_auc:.3f}\\n')\n",
    "        f.write(f'SVM (AUC = {svm_roc_auc:.2f})\\n')\n",
    "        f.write(f'XG Boost (AUC = {xg_roc_auc:.2f})\\n')\n",
    "        f.write(f'Light GBM (AUC = {gbm_roc_auc:.2f})\\n')\n",
    "        f.write(f'k-nearest neighbor AUC: {knn_roc_auc:.3f}\\n')\n",
    "    \n",
    "    # Save the figures\n",
    "    os.makedirs('../out', exist_ok=True)\n",
    "    plt.savefig(f'../out/ROC.png')\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot scoring\n",
    "def getFit (X_train, y_train, model, score, scoring_type):\n",
    "\n",
    "    # Check which model is being scored and choose title\n",
    "    model_titles = {\n",
    "        tree: \"DT\", logr: \"LR\", nb_model: \"NB\",\n",
    "        lda_model: \"LDA\", rf: \"Forest\", svm: \"SVM\",\n",
    "        xg: \"XG Boost\", gbm: \"LightGBM\", knn: \"KNN\"\n",
    "    }\n",
    "\n",
    "    title = model_titles.get(model, \"XG\")\n",
    "\n",
    "    # Compute learning curve\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X_train, y_train, cv=5, scoring= scoring_type, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "    )\n",
    "\n",
    "    # Mapping of scoring types to titles\n",
    "    scoreTitle = {\n",
    "        \"precision\": \"Precision\",\n",
    "        \"neg_log_loss\": \"Log Loss\",\n",
    "        \"balanced_accuracy\": \"B_accuracy\"\n",
    "    }[scoring_type]\n",
    "\n",
    "    # Convert negative log loss scores to positive values for interpretation if scoring type is negative log loss\n",
    "    if scoring_type == 'neg_log_loss':\n",
    "        score = -score\n",
    "        train_scores = -train_scores\n",
    "        val_scores = -val_scores\n",
    "    \n",
    "    # Uncomment once model selection is complete\n",
    "    '''\n",
    "    # Create figure and plot for fitting curve\n",
    "    fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    ax1.plot(train_sizes, train_scores.mean(axis=1), 'o-', label=f\"Training Accuracy {scoreTitle}\", color=\"grey\")\n",
    "    ax1.plot(train_sizes, val_scores.mean(axis=1), 'o-', label=\"Holdout Accuracy\", color=\"black\")\n",
    "    # Graph labels\n",
    "    ax1.set_xlabel(\"Number of samples\")\n",
    "    ax1.set_ylabel(f\"{scoreTitle} (%)\")\n",
    "    ax1.set_title(f\"{title} fitting graph\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Save the figures\n",
    "    os.makedirs('../out', exist_ok=True)\n",
    "    fig1.savefig(f'../out/{title}_fitting_graph_{scoreTitle}.png', dpi=300)\n",
    "    '''\n",
    "\n",
    "    # Save the scores\n",
    "    with open(f'../out/score_summary.txt', \"a\") as f:\n",
    "        f.write(f\"{title}\\n\")\n",
    "        f.write(f\"{scoreTitle}\\n\")\n",
    "        f.write(f\"-----------\\n\")\n",
    "        f.write(f\"Cross-validation scores:\\n{', '.join(map(str, score))}\\n\")\n",
    "        f.write(f\"Mean {scoreTitle}: {score.mean():.4f}\\n\")\n",
    "        f.write(f\"Standard deviation: {score.std():.4f}\\n\\n\")\n",
    "\n",
    "    print(f\"Plots and score's saved successfully in ../out/\")\n",
    "    return fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "# Define possible values\n",
    "config = {   \n",
    "    \"model\": [ \n",
    "        \"tree\", \"logr\", \"nb_model\", \"lda_model\",\n",
    "        \"rf\", \"svm\", \"xg\", \"gbm\", \"knn\"\n",
    "        ],\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"tree\": tree, \"logr\": logr, \"nb_model\": nb_model,\n",
    "    \"lda_model\": lda_model, \"rf\": rf, \"svm\": svm,\n",
    "    \"xg\": xg, \"gbm\": gbm, \"knn\": knn\n",
    "}\n",
    "\n",
    "scoring_type = \"balanced_accuracy\"\n",
    "\n",
    "# Iterate over all combinations\n",
    "for model_name in config[\"model\"]:\n",
    "    model = models[model_name]  # Get the actual model object\n",
    "    \n",
    "    # Plot results based on model type\n",
    "    if model_name in [\"logr\" or \"knn\" or \"svm\"]:\n",
    "        score = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring=scoring_type) ## using log loss scoring to penalizes confidently wrong probabilities to ensure there is well-calibrated probabilities\n",
    "        fig1 = getScore (X_test_scaled, y_test, model) # Score model\n",
    "        fig2 = getFit (X_train_scaled, y_train, model, score, scoring_type=scoring_type) # Plot fitting graph\n",
    " \n",
    "    else:\n",
    "        score = cross_val_score(model, X_train, y_train, cv=5, scoring=scoring_type)\n",
    "        fig1 = getScore (X_test, y_test, model)\n",
    "        fig2 = getFit (X_train, y_train, model, score, scoring_type=scoring_type) \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "aucFig = plotAuc (X_test, X_test_scaled, y_test, logr, tree, rf, lda_model, nb_model, knn, svm, xg, gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on new data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "testing_dataf = pd.read_csv('../data/Cl_F_april_data.csv', encoding='utf-8')\n",
    "\n",
    "window = 5 # set Window to the past 5 days\n",
    "\n",
    "# Compute volatility over window -------------------------------------------------\n",
    "testing_dataf['realized_vol']= testing_dataf['log_return'].rolling(window).std() *np.sqrt(252)\n",
    "testing_dataf['rolling_mean'] = testing_dataf['log_return'].rolling(window).mean() # Rolling mean\n",
    "testing_dataf['rolling_std'] = testing_dataf['log_return'].rolling(window).std() # Rolling standard deviation\n",
    "\n",
    "# Add diffrent established volatility estimators -------------------------------------------------\n",
    "\n",
    "## 1) Parkisons volatility\n",
    "testing_dataf['parkinson_vol'] = np.sqrt((1 / (4 * np.log(2))) * (np.log(testing_dataf['High'] / testing_dataf['Low']) ** 2)) \n",
    "\n",
    "## 2) Garman–Klass\n",
    "testing_dataf['garman_klass'] = np.sqrt(\n",
    "    0.5 * (np.log(testing_dataf['High'] / testing_dataf['Low']) ** 2)\n",
    "  - (2 * np.log(2) - 1) * (np.log(testing_dataf['Close'] / testing_dataf['Open']) ** 2)\n",
    ")\n",
    "\n",
    "## 3) Rogers–Satchell\n",
    "testing_dataf['rogers_satchell'] = np.sqrt(\n",
    "    (np.log(testing_dataf['High'] / testing_dataf['Open']) * \n",
    "     (np.log(testing_dataf['High'] / testing_dataf['Open']) - np.log(testing_dataf['Close'] / testing_dataf['Open'])))\n",
    "  + (np.log(testing_dataf['Low']  / testing_dataf['Open']) * \n",
    "     (np.log(testing_dataf['Low']  / testing_dataf['Open']) - np.log(testing_dataf['Close'] / testing_dataf['Open'])))\n",
    ")\n",
    "\n",
    "## 4) Yang–Zhang\n",
    "###   a) Overnight & open-to-close returns\n",
    "testing_dataf['overnight_ret']    = np.log(testing_dataf['Open'] / testing_dataf['Close'].shift(1))\n",
    "testing_dataf['open_close_ret']   = np.log(testing_dataf['Close'] / testing_dataf['Open'])\n",
    "\n",
    "###   b) rolling variances\n",
    "k = 0.34\n",
    "ov_var = testing_dataf['overnight_ret'].rolling(window).var()       # σ_o^2\n",
    "oc_var = testing_dataf['open_close_ret'].rolling(window).var()      # σ_c^2\n",
    "rs_var = testing_dataf['rogers_satchell']**2                        # σ_RS^2\n",
    "\n",
    "###   c) combine and annualize by sqrt(252)\n",
    "yz_var = ov_var + k * oc_var + (1 - k) * rs_var\n",
    "testing_dataf['yang_zhang'] = np.sqrt(yz_var * 252)\n",
    "\n",
    "## 5) Volume dynamics: daily percentage change in trading volume -------------------------------------------------\n",
    "testing_dataf['volume_change'] = testing_dataf['Volume'].pct_change()\n",
    "#testing_dataf = testing_dataf.dropna() \n",
    "testing_dataf['future_vol'] = testing_dataf['realized_vol'].shift(-window)\n",
    "#testing_dataf = testing_dataf.dropna()\n",
    "testing_dataf['target'] = (testing_dataf['future_vol'] > testing_dataf['realized_vol']).astype(int)\n",
    "\n",
    "## 6) Add new features to improve AUC scores -------------------------------------------------\n",
    "testing_dataf['return_lag1'] = testing_dataf['log_return'].shift(1)\n",
    "testing_dataf['volume_lag1'] = testing_dataf['Volume'].shift(1)\n",
    "\n",
    "def rolling_stats(series, window):\n",
    "    return series.rolling(window).mean(), series.rolling(window).std()\n",
    "\n",
    "testing_dataf['ma_5'], testing_dataf['std_5'] = rolling_stats(testing_dataf['log_return'], 5)\n",
    "testing_dataf['ma_10'], testing_dataf['std_10'] = rolling_stats(testing_dataf['log_return'], 10)\n",
    "testing_dataf['momentum_5'] = testing_dataf['log_return'] - testing_dataf['log_return'].shift(5)\n",
    "testing_dataf['volatility_5'] = testing_dataf['log_return'].rolling(5).std()\n",
    "testing_dataf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two new data records\n",
    "testing_X = testing_dataf[['rolling_std', 'yang_zhang', 'std_5', 'std_10', 'volatility_5']]\n",
    "testing_y = testing_dataf['target']\n",
    "\n",
    "newModel = xg\n",
    "testing_fig1 = getScore(testing_X, testing_y, newModel)\n",
    "plt.show()\n",
    "\n",
    "# Predict probabilities for new data\n",
    "newProb = newModel.predict_proba(testing_X)\n",
    "\n",
    "# Create a probability prediction table\n",
    "seqRank = pd.DataFrame(newProb, columns=['Volatility down (0)', 'Volatility up (1)'])\n",
    "seqRank['Max Probability'] = seqRank.max(axis=1)\n",
    "seqRank['Predicted Class'] = newModel.predict(testing_X)\n",
    "seqRank['Volatility Prediction'] = seqRank['Predicted Class'].apply(lambda x: 'Up' if x == 1 else 'Down')\n",
    "seqRank['Date'] = testing_dataf['Date'].values # Add a date to the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make trades\n",
    "\n",
    "p_up = seqRank['Volatility up (1)']  # Probability of volatility going up\n",
    "p_down = seqRank['Volatility down (0)']  # Probability of volatility going down\n",
    "\n",
    "# Generate trading signals based on thresholds\n",
    "tau0 = 0.8 # Buying confidence threshold\n",
    "tau1 = 0.7 # Selling confidence threshold\n",
    "\n",
    "seqRank['Signal'] = np.where(p_up >= tau0, 1,  # Buy signal if confidence is high for volatility up\n",
    "                     np.where(p_down >= tau1, -1, 0))  # Sell signal if confidence is high for volatility down\n",
    "\n",
    "# Define position sizing logic\n",
    "max_betting_amount  = 100_000  # Base capital for trading\n",
    "seqRank['Order Size'] = np.where(\n",
    "    seqRank['Signal'] == 1, max_betting_amount * (p_up - (1 - p_up)),  # Buy order size\n",
    "    np.where(\n",
    "        seqRank['Signal'] == -1, max_betting_amount * (p_down - (1 - p_down)),  # Sell order size\n",
    "        'No trade'  # No trade\n",
    "    )\n",
    ")\n",
    "\n",
    "# Reorder the columns to make Date the leftmost column\n",
    "seqRank['Signal'] = seqRank['Signal'].apply(lambda x: 'Buy' if x == 1 else ('Sell' if x == -1 else 'No Trade'))\n",
    "probRank = seqRank[['Date', 'Volatility down (0)', 'Volatility up (1)', 'Max Probability', 'Volatility Prediction', 'Signal', 'Order Size']]\n",
    "seqRank = probRank\n",
    "\n",
    "probRank = seqRank.sort_values(by='Max Probability', ascending=False)  # rank by confidence\n",
    "\n",
    "# Save the rank\n",
    "probRank.to_csv('../out/probabilityRankings.csv', index=True) # output rank by probability\n",
    "seqRank.to_csv('../out/sequentialRankings.csv', index=False) # output sort by sequential data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
